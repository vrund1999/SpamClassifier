{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2WV16C6nQ1S"
      },
      "source": [
        "--------------------------------------------------------------------------------\n",
        "2 Logistic Regression Spam Classification\n",
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "I7Ll3ttpnaMc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Cc12hIdYn3et",
        "outputId": "80fb7206-7852-4c28-9c37-1cbdfc96ed8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "JNlp-cVunu44"
      },
      "outputs": [],
      "source": [
        "# Reads in the data, ignoring the first row (header) and first column (index).\n",
        "df = pd.read_csv('gdrive/My Drive/spambase.data')\n",
        "numpyArray = df.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "ZyMTOiJnnyOC"
      },
      "outputs": [],
      "source": [
        "# Randomizes the data\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(numpyArray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "zAMYrK4rn-9P"
      },
      "outputs": [],
      "source": [
        "# Selects the first 2/3 (round up) of the data for training and the remaining for testing\n",
        "trainingData = numpyArray[:math.ceil(len(numpyArray) * 2/3)]\n",
        "testingData = numpyArray[math.ceil(len(numpyArray) * 2/3):]\n",
        "\n",
        "X_train = np.delete(trainingData, -1, axis=1)\n",
        "X_test = np.delete(testingData, -1, axis=1)\n",
        "\n",
        "Y_train =  np.delete(trainingData, slice(0, 57), axis=1)\n",
        "Y_test =  np.delete(testingData, slice(0, 57), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "FueuM0R0omv8"
      },
      "outputs": [],
      "source": [
        "# Standardizes the data (except for the last column of course) using the training data\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0, ddof=1)\n",
        "\n",
        "sX_train = (X_train-mean)/std\n",
        "sX_test = (X_test-mean)/std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "oatWS7u9oqpi"
      },
      "outputs": [],
      "source": [
        "# Add bias to standardized input data\n",
        "sX_train = np.insert(sX_train, 0, 1, axis=1)\n",
        "sX_test = np.insert(sX_test, 0, 1, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "HCA2NiHSosR0"
      },
      "outputs": [],
      "source": [
        "# Use a learning rate Î· = 0.01.\n",
        "learning_rate = .01\n",
        "num_of_features = len(numpyArray[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "iUrckKT-p265"
      },
      "outputs": [],
      "source": [
        "#Set randomized values between [-1,1] for thetas\n",
        "thetas = []\n",
        "for i in range(0, num_of_features):\n",
        "  lst=[]\n",
        "  lst.append(random.uniform(-1.0, 1.0))\n",
        "  thetas.append(lst)\n",
        "\n",
        "thetas = np.array(thetas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "vhNlrAuPqApH"
      },
      "outputs": [],
      "source": [
        "def sigmoid(X, thetas):\n",
        "  return (1 / (1 + np.exp((-1) * X @ thetas)))\n",
        "\n",
        "def log_loss_calc(X_train, Y_train, thetas):\n",
        "  sum = 0\n",
        "  for i in range(len(X_train)):\n",
        "    if((1 - sigmoid(X_train[i], thetas)) < 0):\n",
        "      print(sigmoid(X_train[i], thetas))\n",
        "    if((sigmoid(X_train[i], thetas)) < 0):\n",
        "      print(sigmoid(X_train[i], thetas))\n",
        "    sum += (-Y_train[i] * np.exp(sigmoid(X_train[i], thetas))) - ((1 - Y_train[i]) * np.exp((1 - sigmoid(X_train[i], thetas))))\n",
        "  \n",
        "  return sum\n",
        "\n",
        "def run_batch_gradient_descent(thetas, X_train, X_test, Y_train, Y_test, N, learning_rate, max_iterations):\n",
        "   log_loss = log_loss_calc(X_train, Y_train, thetas)\n",
        "   while(max_iterations >= 1):\n",
        "     thetas  = thetas + ((learning_rate/N) * (X_train.T @ (Y_train - sigmoid(X_train, thetas))))\n",
        "     \n",
        "     new_log_loss = log_loss_calc(X_train, Y_train, thetas)\n",
        "\n",
        "     if(abs(new_log_loss - log_loss) <= 2**-23):\n",
        "       break\n",
        "\n",
        "     log_loss = new_log_loss\n",
        "     \n",
        "     max_iterations -= 1\n",
        "     \n",
        "     #Return the final calculated theta values\n",
        "   return thetas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "txmnAyUJsyso",
        "outputId": "f7f38cee-cdf0-41c1-a184-9d4a4cdf090e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-7152.20025173]\n"
          ]
        }
      ],
      "source": [
        "final_thetas = run_batch_gradient_descent(thetas, sX_train, sX_test, Y_train, Y_test, N=len(trainingData), learning_rate=.01, max_iterations=1500)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "Len3gQs8eZW6"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy(Y_test, sX_test, thetas):\n",
        "  correct = 0\n",
        "  for i in range(len(Y_test)):\n",
        "    obs_class = 0\n",
        "    Prob_1 = sigmoid(sX_test[i], thetas)\n",
        "    Prob_0 = 1 - sigmoid(sX_test[i], thetas)\n",
        "\n",
        "    if(Prob_1[0] > Prob_0[0]):\n",
        "      obs_class = 1\n",
        "    else:\n",
        "      obs_class = 0\n",
        "\n",
        "    if(Y_test[i][0] == obs_class):\n",
        "      correct += 1\n",
        "\n",
        "  return correct/len(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_precision(Y_test, sX_test, thetas):\n",
        "  true_positives = 0\n",
        "  false_positives = 0\n",
        "  for i in range(len(Y_test)):\n",
        "    obs_class = 0\n",
        "    Prob_1 = sigmoid(sX_test[i], thetas)\n",
        "    Prob_0 = 1 - sigmoid(sX_test[i], thetas)\n",
        "\n",
        "    if(Prob_1[0] > Prob_0[0]):\n",
        "      obs_class = 1\n",
        "    else:\n",
        "      obs_class = 0\n",
        "\n",
        "    if(obs_class == 1 and int(Y_test[i]) == 1):\n",
        "      true_positives += 1\n",
        "    if(obs_class == 1 and int(Y_test[i]) == 0):\n",
        "      false_positives += 1\n",
        "  \n",
        "  return (true_positives / (true_positives + false_positives))"
      ],
      "metadata": {
        "id": "804Msct38oyp"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_recall(Y_test, sX_test, thetas):\n",
        "  true_positives = 0\n",
        "  false_negatives = 0\n",
        "  for i in range(len(Y_test)):\n",
        "    obs_class = 0\n",
        "    Prob_1 = sigmoid(sX_test[i], thetas)\n",
        "    Prob_0 = 1 - sigmoid(sX_test[i], thetas)\n",
        "\n",
        "    if(Prob_1[0] > Prob_0[0]):\n",
        "      obs_class = 1\n",
        "    else:\n",
        "      obs_class = 0\n",
        "\n",
        "    if(obs_class == 1 and int(Y_test[i]) == 1):\n",
        "      true_positives += 1\n",
        "    if(obs_class == 0 and int(Y_test[i]) == 1):\n",
        "      false_negatives += 1\n",
        "  \n",
        "  return (true_positives / (true_positives + false_negatives))"
      ],
      "metadata": {
        "id": "STUAskwosae8"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_f_measure(precision, recall):\n",
        "  return ((2 * precision * recall) / (precision + recall))"
      ],
      "metadata": {
        "id": "K_DP3DFxuycB"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_accuracy = calc_accuracy(Y_test, sX_test, final_thetas)"
      ],
      "metadata": {
        "id": "rjQc-7uWw6AQ"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_precision = calc_precision(Y_test, sX_test, final_thetas)"
      ],
      "metadata": {
        "id": "dcDwlvRf65HL"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_recall = calc_recall(Y_test, sX_test, final_thetas)"
      ],
      "metadata": {
        "id": "IqzVgSdg9KLf"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_f_measure = calc_f_measure(LR_precision, LR_recall)"
      ],
      "metadata": {
        "id": "AhI3jH2QutsH"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kAOUdaweuc2W",
        "outputId": "f08b3d70-d2bf-4cf2-8dfe-d77c375e7a60"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8904109589041096"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR_precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "djfHiwaHudZ0",
        "outputId": "0ce19907-f2f9-45f8-b409-aceb23b8612a"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8671454219030521"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR_recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fP9V6fbUud-V",
        "outputId": "8f1b287c-736d-4fa0-d0fa-912ef38661ae"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8370883882149047"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR_f_measure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QhiliCvFueqV",
        "outputId": "85e1594a-1793-4d75-dbb9-52a4f330d087"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8518518518518519"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "3 Naive Bayes Classifier\n",
        "--------------------------------------------------------------------------------\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "SGawZDltvKmE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "Hymmjwn-vpPQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c3c67ac7-5a40-4c12-c613-7b7eb31456c0",
        "id": "5hq1LFU8vpPQ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "m3sAOq9xvpPR"
      },
      "outputs": [],
      "source": [
        "# Reads in the data, ignoring the first row (header) and first column (index).\n",
        "df = pd.read_csv('gdrive/My Drive/spambase.data')\n",
        "numpyArray = df.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "o_-ayJPvvpPR"
      },
      "outputs": [],
      "source": [
        "# Randomizes the data\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(numpyArray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "qsIqMZ_GvpPR"
      },
      "outputs": [],
      "source": [
        "# Selects the first 2/3 (round up) of the data for training and the remaining for testing\n",
        "trainingData = numpyArray[:math.ceil(len(numpyArray) * 2/3)]\n",
        "testingData = numpyArray[math.ceil(len(numpyArray) * 2/3):]\n",
        "\n",
        "X_train = np.delete(trainingData, -1, axis=1)\n",
        "X_test = np.delete(testingData, -1, axis=1)\n",
        "\n",
        "Y_train =  np.delete(trainingData, slice(0, 57), axis=1)\n",
        "Y_test =  np.delete(testingData, slice(0, 57), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "tOyxXkdyvpPR"
      },
      "outputs": [],
      "source": [
        "# Standardizes the data (except for the last column of course) using the training data\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0, ddof=1)\n",
        "\n",
        "sX_train = (X_train-mean)/std\n",
        "sX_test = (X_test-mean)/std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "gqv_NNuavpPR"
      },
      "outputs": [],
      "source": [
        "# Add bias to standardized input data\n",
        "sX_train = np.insert(sX_train, 0, 1, axis=1)\n",
        "sX_test = np.insert(sX_test, 0, 1, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_non_spam_class_prob(Y_test):\n",
        "  total_non_spams = 0\n",
        "  for output in Y_test:\n",
        "    if(int(output[0]) == 0):\n",
        "      total_non_spams += 1\n",
        "  \n",
        "  return (total_non_spams / len(Y_test))"
      ],
      "metadata": {
        "id": "zONWTrlAyThT"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spam_class_prob(Y_test):\n",
        "  total_spams = 0\n",
        "  for output in Y_test:\n",
        "    if(int(output[0]) == 1):\n",
        "      total_spams += 1\n",
        "  \n",
        "  return (total_spams / len(Y_test))"
      ],
      "metadata": {
        "id": "Um_7fgtezRKk"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_spam_class_prob = get_non_spam_class_prob(Y_test)"
      ],
      "metadata": {
        "id": "gWIxWNk3yZwF"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_class_prob = get_spam_class_prob(Y_test)"
      ],
      "metadata": {
        "id": "SwpodTQvzPQl"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_samples = []\n",
        "non_spam_samples = []\n",
        "for row in range(len(sX_train)):\n",
        "  if(int(Y_train[row][0]) == 0):\n",
        "    non_spam_samples.append(sX_train[row])\n",
        "  else:\n",
        "    spam_samples.append(sX_train[row])\n",
        "\n",
        "spam_samples = np.array(spam_samples)\n",
        "non_spam_samples = np.array(non_spam_samples)"
      ],
      "metadata": {
        "id": "SssJ5dynzW71"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_features_mean = np.mean(spam_samples, axis=0)  "
      ],
      "metadata": {
        "id": "5nuabsxe1RXU"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_spam_features_mean = np.mean(non_spam_samples, axis=0)  "
      ],
      "metadata": {
        "id": "9PRKbJLq10rW"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_features_std = np.std(spam_samples, axis=0, ddof=1)"
      ],
      "metadata": {
        "id": "QuTiLyvq11EU"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_spam_features_std = np.std(non_spam_samples, axis=0, ddof=1)"
      ],
      "metadata": {
        "id": "pHIestHe1_8l"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gaussian_approx(feature, mean, std):\n",
        "  exp = (-1) * (( (feature - mean)**2 ) / (2 * (std**2)))\n",
        "  return ( (1 / (std * math.sqrt(2 * math.pi))) * (math.e**exp))"
      ],
      "metadata": {
        "id": "MsAs8Inx91pt"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for i in range(len(sX_test)):\n",
        "  spam_prob = spam_class_prob\n",
        "  non_spam_prob = non_spam_class_prob\n",
        "  for feature_index in range(1, len(sX_test[i])):\n",
        "    spam_gaussian_approx = get_gaussian_approx(sX_test[i][feature_index], spam_features_mean[feature_index], spam_features_std[feature_index])\n",
        "    non_spam_gaussian_approx = get_gaussian_approx(sX_test[i][feature_index], non_spam_features_mean[feature_index], non_spam_features_std[feature_index])\n",
        "\n",
        "    spam_prob *= spam_gaussian_approx\n",
        "    non_spam_prob *= non_spam_gaussian_approx\n",
        "  \n",
        "  if(spam_prob > non_spam_prob):\n",
        "    predictions.append(1)\n",
        "  else:\n",
        "    predictions.append(0)"
      ],
      "metadata": {
        "id": "YDiD46NQ3ARV"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_naive_bayes_accuracy(predictions, Y_test):\n",
        "  correct = 0\n",
        "\n",
        "  for i in range(len(Y_test)):\n",
        "    if(predictions[i] == int(Y_test[i][0])):\n",
        "      correct += 1\n",
        "    \n",
        "  return correct/len(Y_test)"
      ],
      "metadata": {
        "id": "b15DP4hhBuEF"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_naive_bayes_precision(predictions, Y_test):\n",
        "  true_positives = 0\n",
        "  false_positives = 0\n",
        "  for i in range(len(Y_test)):\n",
        "    if(predictions[i] == 1 and int(Y_test[i][0]) == 1):\n",
        "      true_positives += 1\n",
        "    if(predictions[i] == 1 and int(Y_test[i][0]) == 0):\n",
        "      false_positives += 1\n",
        "  \n",
        "  return (true_positives / (true_positives + false_positives))\n"
      ],
      "metadata": {
        "id": "z1b6Ud3FFP-h"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_naive_bayes_recall(predictions, Y_test):\n",
        "  true_positives = 0\n",
        "  false_negatives = 0\n",
        "\n",
        "  for i in range(len(Y_test)):\n",
        "    if(predictions[i] == 1 and int(Y_test[i][0]) == 1):\n",
        "      true_positives += 1\n",
        "    if(predictions[i] == 0 and int(Y_test[i][0]) == 1):\n",
        "      false_negatives += 1\n",
        "  \n",
        "\n",
        "  return (true_positives / (true_positives + false_negatives))"
      ],
      "metadata": {
        "id": "tRqzmO1YF8nL"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_naive_bayes_f_measure(precision, recall):\n",
        "  return ((2 * precision * recall) / (precision + recall))"
      ],
      "metadata": {
        "id": "F0yEy0SmGc0r"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes_accuracy = get_naive_bayes_accuracy(predictions, Y_test)"
      ],
      "metadata": {
        "id": "fOQbQoWXDmym"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_hTQobrdEd21",
        "outputId": "78cada5d-9205-4ac9-951b-22ca495a7d1a"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7879973907371167"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes_precision = get_naive_bayes_precision(predictions, Y_test)"
      ],
      "metadata": {
        "id": "5EDCgajQEexm"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes_precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1rfXs3PFF4z0",
        "outputId": "cfff287a-bad1-4a8d-a744-9e47b29ba833"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6465116279069767"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes_recall = get_naive_bayes_recall(predictions, Y_test)"
      ],
      "metadata": {
        "id": "e79VONwNF51l"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes_recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lNZCHlgfGY_k",
        "outputId": "8e1c2f50-7551-47a1-a506-32d8d09337d9"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9636048526863085"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes_f_measure = get_naive_bayes_f_measure(naive_bayes_precision, naive_bayes_recall)"
      ],
      "metadata": {
        "id": "xDIGJCpSGaEF"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes_f_measure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "T093tTGqGy7U",
        "outputId": "493ac8e7-e31d-4d34-bc29-265cbba8b2b3"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7738343771746694"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "4 Decision Trees\n",
        "--------------------------------------------------------------------------------\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "7i_mXmsiJjRw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "fiyBLpysJqXB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "49822c5c-0045-4cdd-86e5-aafc400ac5a9",
        "id": "EhjDf9FcJqXC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "id": "NtVluUYIJqXD"
      },
      "outputs": [],
      "source": [
        "# Reads in the data, ignoring the first row (header) and first column (index).\n",
        "df = pd.read_csv('gdrive/My Drive/spambase.data')\n",
        "numpyArray = df.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "id": "MPII45AsJqXD"
      },
      "outputs": [],
      "source": [
        "# Randomizes the data\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(numpyArray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {
        "id": "ri6GGa22JqXD"
      },
      "outputs": [],
      "source": [
        "# Selects the first 2/3 (round up) of the data for training and the remaining for testing\n",
        "trainingData = numpyArray[:math.ceil(len(numpyArray) * 2/3)]\n",
        "testingData = numpyArray[math.ceil(len(numpyArray) * 2/3):]\n",
        "\n",
        "X_train = np.delete(trainingData, -1, axis=1)\n",
        "X_test = np.delete(testingData, -1, axis=1)\n",
        "\n",
        "Y_train =  np.delete(trainingData, slice(0, 57), axis=1)\n",
        "Y_test =  np.delete(testingData, slice(0, 57), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "id": "rkU2BM6nJqXE"
      },
      "outputs": [],
      "source": [
        "# Standardizes the data (except for the last column of course) using the training data\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0, ddof=1)\n",
        "\n",
        "sX_train = (X_train-mean)/std\n",
        "sX_test = (X_test-mean)/std\n",
        "\n",
        "sX_train = np.append(sX_train, Y_train, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "id": "L54PkXSjJqXE"
      },
      "outputs": [],
      "source": [
        "#Divides the training data into two groups: Spam samples, Non-Spam samples\n",
        "spam_samples = []\n",
        "non_spam_samples = []\n",
        "for row in range(len(sX_train)):\n",
        "  if(int(sX_train[row][-1]) == 0):\n",
        "    non_spam_samples.append(sX_train[row])\n",
        "  else:\n",
        "    spam_samples.append(sX_train[row])\n",
        "\n",
        "spam_samples = np.array(spam_samples)\n",
        "non_spam_samples = np.array(non_spam_samples)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam_samples_medians = np.median(spam_samples, axis=0)"
      ],
      "metadata": {
        "id": "SoNfQD8AKZeT"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_spam_samples_medians = np.median(non_spam_samples, axis=0)"
      ],
      "metadata": {
        "id": "o3UEkrrwLaB1"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_spam_samples = []\n",
        "for row in range(len(spam_samples)):\n",
        "  lst = []\n",
        "  for i in range(len(spam_samples[row]) - 1):\n",
        "    if(spam_samples[row][i] >= spam_samples_medians[i]):\n",
        "      lst.append(1)\n",
        "    else:\n",
        "      lst.append(0)\n",
        "  lst.append(spam_samples[row][-1])\n",
        "  binary_spam_samples.append(lst)\n",
        "\n",
        "binary_spam_samples = np.array(binary_spam_samples)"
      ],
      "metadata": {
        "id": "qQd61ZjJLb91"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_non_spam_samples = []\n",
        "for row in range(len(non_spam_samples)):\n",
        "  lst = []\n",
        "  for i in range(len(non_spam_samples[row])):\n",
        "    if(non_spam_samples[row][i] >= non_spam_samples_medians[i]):\n",
        "      lst.append(1)\n",
        "    else:\n",
        "      lst.append(0)\n",
        "    \n",
        "  lst.append(non_spam_samples[row][-1])\n",
        "  binary_non_spam_samples.append(lst)\n",
        "\n",
        "binary_non_spam_samples = np.array(binary_non_spam_samples)"
      ],
      "metadata": {
        "id": "nN-561GJL78V"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_spam = (-1) * (len(binary_spam_samples) / (len(binary_spam_samples) + len(binary_non_spam_samples))) * math.log(len(binary_spam_samples) / (len(binary_spam_samples) + len(binary_non_spam_samples)), 2)"
      ],
      "metadata": {
        "id": "YmbFK60ZTl3l"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_non_spam = (-1) * (len(binary_non_spam_samples) / (len(binary_non_spam_samples) + len(binary_spam_samples))) * math.log(len(binary_non_spam_samples) / (len(binary_non_spam_samples) + len(binary_spam_samples)), 2)"
      ],
      "metadata": {
        "id": "bTwiPFRmTorF"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_non_spam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9P_fP6IZhiNB",
        "outputId": "c1416490-b179-475d-bda3-fbbe062b7b38"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4440576038237948"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Entropy of entire system\n",
        "H_data_set = p_non_spam + p_spam"
      ],
      "metadata": {
        "id": "r3XU_D5uhrBS"
      },
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H_data_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bXJBmk-dhzij",
        "outputId": "ebbaf3f9-ec08-4f4e-f5f7-b7cca5139acd"
      },
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.972493094244988"
            ]
          },
          "metadata": {},
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_entropy(totalPositive, totalNegative, totalObs):\n",
        "  if(totalObs <= 0):\n",
        "    return 0\n",
        "  return (-1) * ((totalPositive/totalObs) * math.log(totalPositive/totalObs, 2) + (totalNegative/totalObs) * math.log(totalNegative/totalObs, 2))\n",
        "   "
      ],
      "metadata": {
        "id": "msuvVay7h0XT"
      },
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_entropy(data):\n",
        "  classValues = np.delete(data, slice(0, 57), axis=1)\n",
        "  classValues = classValues.astype(int)\n",
        "  values, counts = np.unique(classValues, return_counts=True)\n",
        "  entropy = 0\n",
        "\n",
        "  for value in values:\n",
        "    prob = counts[value]/len(classValues)\n",
        "    entropy += -prob * np.log2(prob)\n",
        "  return entropy"
      ],
      "metadata": {
        "id": "T8hNoyN0C4md"
      },
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_entropy_attribute(data, attribute_index):\n",
        "  #Class = df.keys()[-1]\n",
        "  classValues = np.delete(data, slice(0, 57), axis=1)\n",
        "  classValues = classValues.astype(int)\n",
        "  #target_values = df[Class].unique()\n",
        "  values, counts = np.unique(classValues, return_counts=True)\n",
        "\n",
        "  #attribute_values = df[attribute].unique()\n",
        "  attributeValues = data[:, [attribute_index]]\n",
        "  attributeValuesUnique = np.unique(attributeValues)\n",
        "\n",
        "  avg_entropy = 0\n",
        "  for value in attributeValuesUnique:\n",
        "    entropy = 0\n",
        "    for value1 in values:\n",
        "      numerator = 1\n",
        "      denominator = 1\n",
        "      for row in range(len(data)):\n",
        "        if(data[row][attribute_index] == value and data[row][-1] == value1):\n",
        "          numerator += 1\n",
        "        if(data[row][attribute_index] == value):\n",
        "          denominator += 1\n",
        "\n",
        "      entropy += -(numerator/denominator) * np.log2((numerator/denominator) + 0.00000001)\n",
        "    avg_entropy += (denominator/len(data))*entropy\n",
        "  return avg_entropy\n"
      ],
      "metadata": {
        "id": "2W099OH2Ddzr"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_attribute(data):\n",
        "  information_gains = []\n",
        "  for i in range(len(data[0])):\n",
        "    information_gains.append(find_entropy(data) - find_entropy_attribute(data, i))\n",
        "  \n",
        "  max = 0\n",
        "  index = 0\n",
        "\n",
        "  for i in range(len(information_gains)):\n",
        "    if(information_gains[i] > max):\n",
        "      max = information_gains[i]\n",
        "      index = i\n",
        "\n",
        "  return i"
      ],
      "metadata": {
        "id": "d_LmqLEzHxaN"
      },
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_entropy(sX_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Iz7TlNdPSW4D",
        "outputId": "caba495a-0b10-497f-b185-a024208dc9bd"
      },
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.972493094244988"
            ]
          },
          "metadata": {},
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_entropy_attribute(sX_train, 57)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BGRzyM_is_Wi",
        "outputId": "2ec14073-b3e2-451a-db6e-fa310ca56c7d"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.006883392744106848"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_attribute(sX_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "G6EhFsRGHCET",
        "outputId": "fc66a557-4fa0-45b9-e12a-2e993472273d"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {},
          "execution_count": 326
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def DTL(samples, attributes, defaultTree = None):\n",
        "  if(len(examples) == 0):\n",
        "    return defaultTree\n",
        "  elif(sameClassification(examples)[0] == True):\n",
        "    return sameClassification(examples)[1]\n",
        "  elif(len(attributes) == 0):\n",
        "    return Mode(samples)\n",
        "  else:\n",
        "    bestAtt = ChooseAttribute(attributes, samples)\n",
        "    tree = {}\n",
        "    tree[bestAtt] = None\n",
        "    for value in bestAtt:\n",
        "      samples[bestAtt]"
      ],
      "metadata": {
        "id": "XshBX9kl87xA"
      },
      "execution_count": 327,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CS383 - Assn2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}